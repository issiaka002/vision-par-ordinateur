{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "Survol-Apprentissage_Automatique_Classique-Iris.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SaK0iuCygKex",
        "vg-TYDGBgKex",
        "X_Ggj2OJgKex",
        "T50PVG7ZgKex"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2dGqvMYgKeP"
      },
      "source": [
        "<a style=\"float:left;\" href=\"https://colab.research.google.com/github/ClaudeCoulombe/VIARENA/blob/master/Labos/Lab-Iris/Survol-Apprentissage_Automatique_Classique-Iris.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<br/>\n",
        "### Rappel - Fonctionnement d'un carnet web iPython\n",
        "\n",
        "* Pour exécuter le code contenu dans une cellule d'un carnet iPython, cliquez dans la cellule et faites (⇧↵, shift-enter)\n",
        "* Le code d'un carnet iPython s'exécute séquentiellement de haut en bas de la page. Souvent, l'importation d'une bibliothèque Python ou l'initialisation d'une variable est préalable à l'exécution d'une cellule située plus bas. Il est donc recommandé d'exécuter les cellules en séquence. Enfin, méfiez-vous des retours en arrière qui peuvent réinitialiser certaines variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cPMZ-S6gKea"
      },
      "source": [
        "<h1 style=\"font-size:250%;text-align:center\">Survol de l'apprentissage automatique classique</h1>\n",
        "<h1 style=\"font-size:250%;text-align:center\">avec le jeu de données des Iris gaspésiens</h1>\n",
        "<h1 style=\"font-size:250%;text-align:center\">et Scikit-Learn (Sklearn)</h1>\n",
        "<br/><br/>\n",
        "<img src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@ScDo-ScikitLearn-logo.jpeg\" width=300 style=\"float:center;\"/>\n",
        "<br/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrL_GJDNgKeb"
      },
      "source": [
        "## Importation des bibliothèques utilisées pour le tutoriel\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo8Oj8jsgKeb"
      },
      "source": [
        "# Importer toutes les bibliothèques, classes et fonctions\n",
        "# utilisées pour le tutoriel dans l'espace de travail\n",
        "import scipy # bibliothèque de calcul scientifique\n",
        "import matplotlib # bibliothèque d'affichage graphique\n",
        "import sklearn # bibliothèque d'algorithmes \"classiques\" d'apprentissage automatique\n",
        "\n",
        "# Pour de grosses bibliothèques, vous pouvez importer seulement des parties\n",
        "# avec from <bibliothèque> import <classe/objet>\n",
        "# Note: «import *» importe le code de TOUS les paquets (packages),\n",
        "from numpy import * # bibliothèque de calcul matriciel\n",
        "from pandas import * # bibliothèque de manipulation de tableaux de données\n",
        "from sklearn import * # bibliothèque d'algorithmes \"classiques\" d'apprentissage automatique\n",
        "\n",
        "# Important: pour éviter des conflits dans l'espace de nommage,\n",
        "# vous pouvez renommer les bibliothèques importées\n",
        "\n",
        "# Renommages conventionnels:\n",
        "## import <bibliothèque> as <abréviation>\n",
        "# numpy devient «np»\n",
        "import numpy as np\n",
        "## matplotlib devient «plt»\n",
        "import matplotlib.pyplot as plt\n",
        "# La manière usuelle d'importer Pandas\n",
        "# Importer la biblothèque Pandas et la renommer «pd»\n",
        "import pandas as pd\n",
        "\n",
        "# Pour de grosses bibliothèques, vous pouvez importer seulement des parties\n",
        "# avec from <bibliothèque> import <classe/objet>\n",
        "# Importer les classes «Series» et «DataFrame» de Pandas\n",
        "from pandas import Series, DataFrame\n",
        "\n",
        "# Importer des classes ou fonctions spécifiques d'une bibliothèque\n",
        "# from <bibliotheque> import <fonction>\n",
        "from pandas import DataFrame, read_csv\n",
        "\n",
        "# Activer l'affichage des graphiques dans la page du Notebook iPython\n",
        "%matplotlib inline\n",
        "\n",
        "# Importer IPython afin de pouvoir vérifier sa version et d'afficher des contenus web dans le carnet\n",
        "import IPython\n",
        "\n",
        "# Bibliothèque «sys», utilisée uniquement pour obtenir les numéros de versions\n",
        "import sys\n",
        "\n",
        "print(\"Bibliothèques Python importées\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_aQX3NogKeg"
      },
      "source": [
        "### Vérification de l'installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAN_Xfh2gKeg"
      },
      "source": [
        "# Vérification des versions des bibliothèques Python importées\n",
        "print('Version de Python: ',sys.version)\n",
        "print('Version de IPython: ',IPython.__version__)\n",
        "print('Version de NumPy: ',np.__version__)\n",
        "print('Version de Matplotlib: ',matplotlib.__version__)\n",
        "print('Version de SciPy: ',scipy.__version__)\n",
        "print('Version de Pandas: ',pd.__version__)\n",
        "print('Version de Scikit-Learn: ',sklearn.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixer le hasard pour la reproductibilité\n",
        "\n",
        "L'apprentissage automatique implique parfois des processus aléatoires. Afin de pouvoir reproduire et comparer vos résultats d'expérience, vous allez fixer temporairement l'état aléatoire grâce à un germe aléatoire unique.\n",
        "\n",
        "Pendant la mise au point, vous fixez temporairement l'état aléatoire pour la reproductibilité mais vous répétez l'expérience avec différents germes ou états aléatoires et prenez la moyenne des résultats.\n",
        "<br/>\n",
        "##### **Note**: Pour un système en production, vous ravivez simplement l'état  purement aléatoire avec l'instruction `GERME_ALEATOIRE = None`"
      ],
      "metadata": {
        "id": "YHP0MZv6gG8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Définir un germe aléatoire\n",
        "GERME_ALEATOIRE = 21\n",
        "\n",
        "# Définir un état aléatoire pour Python\n",
        "os.environ['PYTHONHASHSEED'] = str(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour Python random\n",
        "import random\n",
        "random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "# Définir un état aléatoire pour NumPy\n",
        "import numpy as np\n",
        "np.random.seed(GERME_ALEATOIRE)\n",
        "\n",
        "print(\"Germe aléatoire fixé\")"
      ],
      "metadata": {
        "id": "QclOb2J2gTou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7PRofujgKeh"
      },
      "source": [
        "## Lecture et chargement des données\n",
        "\n",
        "Nous allons utiliser le célèbre jeu de de données sur les fleurs d'iris de Gaspésie.\n",
        "\n",
        "Rappelons que ce jeu de données contient 150 observations ou exemplaires de fleurs d'iris. Chaque observation comporte quatre attributs (longueur et la largeur des pétales et des sépales) mesurés sur des fleurs d'iris de trois espèces différentes (Iris setosa, Iris versicolor, Iris virginica).\n",
        "\n",
        "Cela donne un tableau de cinq colonnes, les quatre premières colonnes contiennent des mesures des fleurs en centimètres. La cinquième colonne contient l'étiquette de classe qui est l'espèce de la fleur observée.\n",
        "\n",
        "<ol>\n",
        "    <li>longueur des sépales en cm</li>\n",
        "    <li>largeur des sépales en cm</li>\n",
        "    <li>longueur des pétales en cm</li>\n",
        "    <li>largeur des pétales en cm</li>\n",
        "    <li>espèces (étiquette de classe): \"Iris-setosa\", ou \"Iris-versicolor\", ou \"Iris-virginica\"</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D791XjgHgKei"
      },
      "source": [
        "### Téléchargement des données 'iris.data' du site de l'université de Californie à Irvine\n",
        "\n",
        "<a href=\"https://archive.ics.uci.edu/ml/index.php/\" target=\"_blank\">UCI Machine Learning Repository</a>\n",
        "\n",
        "Note: le jeu de données 'iris.data' qui est en format .csv (comma separated value), sera téléchargés dans le répertoire local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIplyJycgKej"
      },
      "source": [
        "# Commande Linux pour connaître le chemin du répertoire local\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvsB8pV3gKek"
      },
      "source": [
        "# Commande Linux pour télécharger un fichier è partir de son URL\n",
        "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
        "print(\"Données Iris téléchargées\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeL75t97gKel"
      },
      "source": [
        "### Lecture des données - fonction Pandas `read_csv()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6D5NFoAgKel"
      },
      "source": [
        "# Création d'une liste de noms d'attributs en français\n",
        "noms_attributs = [\"longueur_sépales\",\"largeur_sépales\",\"longueur_pétales\",\"largeur_pétales\", \"espèce\"]\n",
        "\n",
        "# pd.read_csv(...) cette fonction de Pandas Retourne un Dataframe ou tableau de données analogue à un tableur\n",
        "# où chaque ligne représente un exemplaire de données (observations ou exemples)\n",
        "# et chaque colonne représente la valeur d'un attribut (ou caractéristique).\n",
        "donnees_iris_df = pd.read_csv(\"./iris.data\", names=noms_attributs)\n",
        "print(\"Données Iris lues et mémorisées dans la variable 'donnees_iris_df'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymJJj_9k3dxm"
      },
      "source": [
        "# Commande Linux pour afficher le contenu du répertoire 'content'\n",
        "!ls /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8exhS-t2gKem"
      },
      "source": [
        "## Exploration des données\n",
        "\n",
        "L’analyse des données débute généralement par l'exploration et la visualisation des données. On cherche ici à se familiariser, mieux comprendre et détecter des éventuelles anomalies comme les données aberrantes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBtBEQifgKem"
      },
      "source": [
        "### Échantillonnage - fonction Dataframe `.sample()`\n",
        "\n",
        "En utilisant la fonction `.sample()` de DataFrame, nous allons choisir au hasard 12 exemplaires de données.\n",
        "\n",
        "Le paramètre `random_state` fixé arbitrairement à 42 assure que le tirage est reproductible\n",
        "<hr/>\n",
        "Note culture: <a ref=\"https://fr.wikipedia.org/wiki/42_(nombre)#Fiction\">42 est la réponse à la grande question dans 'Le Guide du voyageur galactique'</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd0isrF5gKem"
      },
      "source": [
        "# Ci-dessous, nous procédons au tirage de 12 exemplaires des\n",
        "# données d'entraînement. Le paramètre `random_state` fixé\n",
        "# arbitrairement à 42 assure que le tirage est reproductible\n",
        "donnees_iris_df.sample(n= 12, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzFKsX7CgKen"
      },
      "source": [
        "### Vues récapitulatives, l'attribut DataFrame `.shape` et la fonction DataFrame `.describe()`\n",
        "\n",
        "Une seconde étape consiste à explorer chaque attribut (ou caractéristique) pour en connaître la distribution statistique. Par exemple, les différentes valeurs, l’étendue (valeur minimale, valeur maximale), la moyenne, et la variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6mC-Go9gKen"
      },
      "source": [
        "#### Format du tableau de données - l'attribut DataFrame `.shape`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExZq2RmngKen"
      },
      "source": [
        "donnees_iris_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9eWO3MTgKeo"
      },
      "source": [
        "On voit que le fichier comporte 150 lignes ou exemplaires et 5 colonnes ou attributs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YMb9ueugKeo"
      },
      "source": [
        "#### Obtenir le nom des colonnes ou attributs du tableau de données - l'attribut DataFframe `.columns`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PKST58RgKeo"
      },
      "source": [
        "donnees_iris_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOH1-8eygKeo"
      },
      "source": [
        "#### Statistiques descriptives globales du tableau de données - fonction DataFrame `.describe()`\n",
        "\n",
        "Maintenant, examinons notre tableau de données avec la fonction DataFrame `.describe()`\n",
        "\n",
        "La fonction `describe()` retourne plusieurs statistiques sommaires d'un seul coup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkiJgOfUgKep"
      },
      "source": [
        "donnees_iris_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK9s2eOfgKep"
      },
      "source": [
        "On voit ci-haut que le DataFrame «donnees_iris_df» comporte 150 rangées qui correspondent à autant d'observations ou exemplaires de données sur les fleurs d'Iris. Par exemple, la longueur moyenne des sépales est 5.84 cm, la longueur minimale des sépales est 4.3 cm, la longueur au 1er quartile Q1 (25%) est de 5.1 cm (i.e. 25% des mesures sont < 5.1 cm)  la médiane Q2 (50%) est de 5.8 cm (i.e. 50% des mesures sont < 5.8 cm), la longueur du 3e quartile (75%) est de 6.4 cm (i.e. 75% des mesures sont < 6.4 cm), la longueur maximale des sépales est 7.9 cm. On remarquera aussi, que les attributs catégoriels comme 'espèce' ne sont pas considérés par la fonction `.describe()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTdyw20CgKep"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJQUr0ojgKep"
      },
      "source": [
        "### Chargement des bibliothèques de scikit-learn ou `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_GoT8ucgKeq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Bibliothèques Sklearn importées\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeUXfPxfgKeq"
      },
      "source": [
        "### Détermination de la classe-cible et des prédicteurs\n",
        "\n",
        "Nous cherchons à prédire l'espèce de l'iris à partir des mesures de la longueur et la largeur des pétales et des sépales de fleurs d'iris. La cible (ou classe-cible) sera `espèce` et les prédicteurs (ou attributs-prédicteurs) seront: `espèce_Iris-setosa`, `espèce_Iris-versicolor`, `espèce_Iris-virginica`.    \n",
        "\n",
        "Note terminologie:\n",
        "\n",
        "* classe-cible, cible ou classe, ou prédiction, ou variable dépendante sont des termes équivalents\n",
        "* prédicteurs, ou attributs ou variables indépendantes sont des termes équivalents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIAIxXUSgKeq"
      },
      "source": [
        "#### Séparation de la cible et des prédicteurs\n",
        "\n",
        "Puisque le but est de prédire la cible (ou classe-cible), il faut donc l'isoler des autres attributs prédicteurs pour constituer l'ensemble des cibles. Rappelons que dans notre exemple, les cibles prennent les valeurs: \"espèce_Iris-setosa\", \"espèce_Iris-versicolor\", \"espèce_Iris-virginica\". On crée également un autre ensemble contenant les prédicteurs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iIOIg_hgKeq"
      },
      "source": [
        "cibles_df = donnees_iris_df['espèce']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heGfpst5gKeq"
      },
      "source": [
        "cibles_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDmWRjeLgKer"
      },
      "source": [
        "cibles_df.sample(n= 12, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qKzOHPIgKer"
      },
      "source": [
        "predicteurs_df = donnees_iris_df.drop(['espèce'],axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSM5eo6XgKer"
      },
      "source": [
        "predicteurs_df.sample(n= 12, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxOFAs94gKer"
      },
      "source": [
        "predicteurs_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aQNbBvdgKes"
      },
      "source": [
        "### Établissement d'une base de référence\n",
        "\n",
        "Nous allons calculer le pourcentage de chaque classe-cible sur la base de la statistique descriptive, il existe de nombreuses façons d'y parvenir.\n",
        "\n",
        "Ce résultat nous donnera une base de référence (baseline) et un modèle de décision à une règle (OneR) qui consiste à prédire l'espèce de l'iris uniquement sur la base de statistiques sans faire intervenir l'apprentissage automatique.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhidwinMgKet"
      },
      "source": [
        "# On calcule la moyenne `mean()` des cas où la classe-cible correspond à une valeur donnée\n",
        "print(\"Iris-setosa:{pourcent: .2f} %\".format(pourcent=np.mean(cibles_df == \"Iris-setosa\")*100))\n",
        "print(\"Iris-versicolor:{pourcent: .2f} %\".format(pourcent=np.mean(cibles_df == \"Iris-versicolor\")*100))\n",
        "print(\"Iris-virginica:{pourcent: .2f} %\".format(pourcent=np.mean(cibles_df == \"Iris-virginica\")*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXMdoG_cgKeu"
      },
      "source": [
        "Sans trop de surprise, on trouve que nos trois classes-cibles sont distribuées également ce qui correcpond à 33%.\n",
        "\n",
        "Donc la base de référence à battre est 33.33 % de bonne prévision pour chaque étiquette.\n",
        "\n",
        "L'idée du modèle de décision à une règle (OneR) est simple. On a tout simplement à prévoir systématiquement une espèce, par exemple `Iris-versicolor` et on aura statistiquement raison 1 fois sur 3. C'est la référence de base de notre modèle.\n",
        "\n",
        "Cela ne veut pas dire que nous serons satisfaits par ce résultat et il faudra se fixer un objectif plus ambitieux comme 90 % par exemple. L'objectif pourra être fixé par les besoins de l'application. Une façon usuelle est de se comparer à la performance d'une personne ayant reçu un formation minimale ou encore un expert botaniste que l'on scherche à assister ou à remplacer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbIjENsSgKeu"
      },
      "source": [
        "cibles_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgLBobKEgKev"
      },
      "source": [
        "### Préparation des données pour Scikit-Learn\n",
        "\n",
        "Scikit-Learn exige que les attributs prennent des valeurs numériques avec décimales. Il faut donc convertir les valeurs catégorielles en valeurs numériques. Il faut également qu'il n'y ait pas de valeur manquante dans les données.   \n",
        "\n",
        "Aussi, Scikit-Learn s'attend que les attributs se trouvent dans un tableau où chaque colonne est un attribut et chaque ligne un exemplaire de données (observation ou point de données)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj_6gp7KgKev"
      },
      "source": [
        "#### Encodage des attributs catégoriels - fonction Sklearn `LabelEncoder()`\n",
        "\n",
        "Rappelons qu'un attribut catégoriel prend des valeurs d'étiquettes symboliques. Par exemple, l'attribut \"couleur\" peut prendre les valeurs \"rouge\", \"vert\" et \"bleu\". Les algorithmes d'apprentissage automatique dont les réseaux de neurones profonds exigent que les variables d'entrée soient des nombres. Il faut donc encoder les données catégorielles en nombres avant de les utiliser pour entraîner un modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7FIMDVPgKev"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encodeur = LabelEncoder()\n",
        "encodeur.fit(cibles_df.values)\n",
        "cibles = encodeur.transform(cibles_df)\n",
        "# Afficher les dix premières cibles\n",
        "cibles [:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GwCdZ9SgKev"
      },
      "source": [
        "#### Conversion des données en nombre avec décimales\n",
        "\n",
        "Idéalement, toutes les valeurs d'attributs devraient être converties en un nombre avec décimales normalisé entre 0 et 1 car certains algorithmes de Scikit-Learn sont sensibles à la grandeur des différents attributs.\n",
        "\n",
        "\n",
        "Il existe des fonctions dans Scikit-Learn pour nous aider.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYONGUVCgKev"
      },
      "source": [
        "predicteurs = predicteurs_df.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s1XfemigKev"
      },
      "source": [
        "### Division en données d'entraînement et de test - fonction Sklearn `train_test_split()`\n",
        "\n",
        "Nous allons retenir une partie des données dans un jeu de données de test que l'algorithme ne verra pas et nous utiliserons ces données pour avoir une idée des performances du modèle sur des données inconnues.\n",
        "\n",
        "Nous diviserons l'ensemble de données en deux, dont typiquement 80 % serviront à l'entraînement, à l'évaluation et à la sélection parmi nos modèles, et 20 % seront retenues comme ensemble de données de test.\n",
        "\n",
        "<ul>\n",
        "    <li>Dans un premier temps, nous allons partager les données entre un ensemble de données d'entraînement et un ensemble de données de test. Les données de test seront isolées et conservées pour évaluer la performance finale des algorithmes sur des données fraîches. C'est ce qu'on appelle la mesure de l'erreur de généralisation.</li>\n",
        "</ul>\n",
        "\n",
        "Note technique: Le paramètre de stratification `stratify` s'assure que la répartition aléatoire des données de `train_test_split()` respecte la proportion de valeurs dans l'échantillon fourni à `stratify`. Ceci est particulièrement important pour les petits jeux de données où la répartition aléatoire des données peut retourner des résultats très différents d'une fois à l'autre.\n",
        "\n",
        "Par exemple, si la classe-cible `cibles_df` est un attribut catégoriel avec 3 valeurs réparties également comme dans l'exemple des données sur les Iris, l'affectaion `stratify=cibles_df` assurera que la répartition aléatoire respecte ce ratio. Évidemment s'il n'y a pas de répartition aléatoire et que le paramètre `shuffle=False`, alors `stratify=None`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKUnsyUHgKew"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Le jeu de données de test contient 20% des données initiales\n",
        "# Note: ce ratio peut varier en fonction de la taille du jeu de données\n",
        "test_ratio = 0.20\n",
        "\n",
        "# Isoler les données de test\n",
        "predicteurs_ent, predicteurs_test, cibles_ent, cibles_test = train_test_split(predicteurs,\n",
        "                                                                              cibles,\n",
        "                                                                              test_size=test_ratio,\n",
        "                                                                              stratify=cibles_df,\n",
        "                                                                              random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JzyYZiDgKew"
      },
      "source": [
        "print(\"Dimensions de predicteurs entrainement:\",predicteurs_ent.shape)\n",
        "print(\"Dimensions de predicteurs test:\",predicteurs_test.shape)\n",
        "print(\"Dimensions de cibles entrainement:\",cibles_ent.shape)\n",
        "print(\"Dimensions de cibles test:\",cibles_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vozz17-cgKew"
      },
      "source": [
        "cibles_ent, cibles_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI8O-dzBgKex"
      },
      "source": [
        "### Choix de différents algorithmes de classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaK0iuCygKex"
      },
      "source": [
        "#### La régression logistique (sic) ou classification logistique\n",
        "\n",
        "La régression logistique porte mal son nom, car il ne s’agit pas d’une régression où l'on prédit un nombre mais bien d'une classification entre  classes-cibles. En fait, la régression logistique qui calcule une probabilité devient la classification logistique, un algorithme de classification, quand on la combine à une règle de décision. Si la probabilité est plus grand ou égal à 0.5 le résultat est 1, si le résultats est plus petit que 0.5, le résultat est 0.\n",
        "\n",
        "Le calcul de la probabilité est basé sur la fonction $\\large{logistique(x) = \\frac{L}{1+Ce^{-k(x-x_0}}}$ dont la fonction $\\large sigmoïde(x)=\\frac{1}{1+e^{-x}}$ est un cas particulier avec $L=1, C=1, k=1, x_0=0$. Notez en passant que la sigmoïde est utilisée dans les réseaux de neurones.\n",
        "\n",
        "Ici, nous allons utiliser la classification logistique multinomiale qui est une extension de la classification logistique pour les situations à trois classes-cibles ou plus.\n",
        "\n",
        "La classification logistique est un algorithme simple et robuste avec un bon pouvoir de généralisation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg-TYDGBgKex"
      },
      "source": [
        "#### Les algorithmes ensemblistes à base d'arbres\n",
        "\n",
        "Depuis quelques années on observe dans les compétitions <a href=\"https://fr.wikipedia.org/wiki/Kaggle\" target=\"_blank\">Kaggle</a> et les articles scientifiques que les meilleurs algorithmes pour traiter des jeu de données de petite taille (#exemplaires < 100 000) et de faibles dimensions (#attributs < 5000) sont souvent des ensembles d'arbres de décision.\n",
        "\n",
        "Ce sont deux algorithmes dit d'apprentissage ensembliste où chaque sous-échantillon correspond à un modèle distinct représenté par un <a href=\"https://fr.wikipedia.org/wiki/Arbre_de_d%C3%A9cision_(apprentissage)\" target=\"_blank\">arbre de décision</a>.\n",
        "\n",
        "Scikit-Learn offre la possibilité d'élaborer des modèles non linéaires à base d'arbres qui sont connus pour bien performer dans des situations où le nombre d'attributs n'est pas très grand (moins de 5000). Nous allons expérimenter la forêt aléatoire (random forests) et les arbres à dopage de gradient (gradient boosting trees).\n",
        "\n",
        "**Note**: Pour les gros jeux de données (#exemplaires > 100 000), dont au moins 5000 par cible, et pour des données en haute dimension (#attribut > 5000), les réseaux de neurones profonds s'avèrent généralement plus performants.\n",
        "\n",
        "Référence: https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_Ggj2OJgKex"
      },
      "source": [
        "#### Forêt aléatoire\n",
        "\n",
        "La forêt aléatoire (random forest classifier) aussi appelées forêt d'arbres décisionnels, a été formellement proposée en 2001 par Leo Breiman et Adèle Cutler. Elle fait partie des techniques d'apprentissage ensembliste qui effectuent un apprentissage sur de multiples arbres de décision entraînés sur des sous-ensembles de données légèrement différents.\n",
        "\n",
        "La forêt aléatoire se base sur l'agrégation par ré-échantillonnage ensembliste (en anglais, bagging pour bootstrap aggregation). Typiquement, le ré-échantillonnage ensembliste aide à réduire la variance et le surajustement. L'algorithme de la forêt aléatoire (en anglais, random forest) est une extension très utilisée du ré-échantillonnage ensembliste.  \n",
        "\n",
        "Le résultat sera obtenu par le calcul de la moyenne pour une régression (prédiction d'un nombre) ou par un vote majoritaire dans le cas d'une classification (prédiction d'une classe-cible)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T50PVG7ZgKex"
      },
      "source": [
        "#### Arbres à gradient dopé - XGBoost\n",
        "\n",
        "Les arbres à gradient dopé (gradient boosting trees) se basent sur un méta-algorithme d'apprentissage ensembliste qui agrège itérativement des classificateurs faibles créés et pondérés selon leur performance pour former un classificateur final fort (capacité plus élevée, biais réduit), en l'occurrence ici des arbres de décisions.\n",
        "\n",
        "Par itérations successives, des classificateurs faibles (faible capacité, biais élevé), sous la forme de petits arbres de décision, sont ajoutés un à un à un ensemble d'arbres en utilisant une fonction de coût optimisée par descente de gradient.\n",
        "\n",
        "Au moment de l'ajout d'un classificateur faible, la pondération des exemples de données (ou points de données) est réajustée (re-pondération) où les exemples mal classés gagnent du poids et les exemples bien classées perdent du poids. Ainsi, un nouveau classificateur faible se concentrera davantage sur les exemples mal classés par les classificateurs faibles précédents pour corriger leur influence. Rappelons qu'un classificateur faible est un classificateur capable de distinguer deux classes au moins aussi bien que le hasard ne le permet (il ne se trompe donc pas plus d'une fois sur deux en moyenne, si la distribution des classes est équilibrée). Des algorithmes très populaires appliquent le dopage de gradient comme l'incontournable XGBoost et AdaBoost (abréviation du terme adaptative boosting) qui a maintenant surtout une importance historique.\n",
        "\n",
        "Note: Pour plus de généralité, on pourrait remplacer le mot «classificateur» par «modèle»\n",
        "\n",
        "XGBoost en est un très bon exemple, XGBoost pour Extreme Gradient Boosting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ICTa7E8gKey"
      },
      "source": [
        "### Validation croisée - fonction Sklearn `StratifiedKFold()`\n",
        "\n",
        "<ul>\n",
        "    <li>Dans une deuxième temps, la recherche des meilleurs hyperparamètres sera effectuée avec les données d'entraînement ce qui impliquera la création d'ensembles de validation avec la validation croisée.</li>\n",
        "</ul>\n",
        "\n",
        "Nous avons déjà divisé les données de façon aléatoire entre des données d'entraînement (80 %) et des données de test vierges (20 %) afin d'évaluer le modèle.\n",
        "\n",
        "La validation croisée permet de comparer des modèles et d'ajuster des hyperparamètres sans nécessiter un ensemble de validation séparé. Ceci préserve de précieuses données d’entraînement. Plus précisément, nous procéderons à une validation croisée à n plis (n-fold cross validation).\n",
        "\n",
        "<img src=\"https://cours.edulib.org/asset-v1:Cegep-Matane+VAERN.1FR+P2021+type@asset+block@Validation_croisee.png\" width=700 style=\"float:center;\"/>\n",
        "\n",
        " Au lieu de diviser nos données une seule fois, nous allons recommencer plusieurs fois et calculer le min, le max et la moyenne des scores comme une meilleure estimation du score réel.\n",
        "\n",
        "\n",
        "Référence: https://scikit-learn.org/stable/modules/cross_validation.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KapWyRMogKe0"
      },
      "source": [
        "### Outils d'évaluation d'un modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbQApAUZgKe0"
      },
      "source": [
        "#### Matrice de confusion\n",
        "\n",
        "Il est possible de voir le détail des faux positifs et des faux négatifs en affichant la matrice de confusion (confusion matrix).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDWBCCFhgKe1"
      },
      "source": [
        "def afficher_matrice_confusion(cm, noms_etiquettes = [u'classe - 0', u'classe - 1', u'classe - 3'],\n",
        "                   titre=u'Matrice de confusion'):\n",
        "#     plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    print(\"\\n\",cm,\"\\n\")\n",
        "    plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "    plt.title(titre)\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks = np.arange(len(noms_etiquettes))\n",
        "    plt.xticks(tick_marks, noms_etiquettes, rotation=60)\n",
        "    plt.yticks(tick_marks, noms_etiquettes)\n",
        "    plt.ylabel(u'Vraie étiquette')\n",
        "    plt.xlabel(u'Étiquette prédite')\n",
        "    # Fonction d'ajustement\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qitil-RPgKe1"
      },
      "source": [
        "# Test de la fonction D,affichage avec ds données fictives\n",
        "matrice_confusion = np.array([[7,  2,  1],[ 2,  6,  2],[ 0,  0, 10]])\n",
        "noms_etiquettes = ['Iris-setosa','Iris-versicolor', 'Iris-virginica']\n",
        "afficher_matrice_confusion(matrice_confusion, noms_etiquettes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1ZVoKPogKe2"
      },
      "source": [
        "### Autres méthodes d'évaluation d'un modèle d'apprentissage\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6eg6JNpgKe2"
      },
      "source": [
        "### Évaluation du modèle avec les données de validation\n",
        "\n",
        "* Définissez une métrique pour évaluer votre modèle;\n",
        "* Quel niveau de performance souhaitez-vous?\n",
        "* Commencez avec un modèle simple\n",
        "* Itérez tant que vous n'atteignez pas le niveau de performance attendu:\n",
        "    * Est-ce que l'erreur d'entraînement est élevée?\n",
        "        * OUI (biais élevé):\n",
        "            * Essayez un modèle plus complexe\n",
        "            * Entraînez plus longtemps\n",
        "        * NON:\n",
        "            * Est-ce que l'erreur de validation est élevée?\n",
        "                * OUI (variance élevée):\n",
        "                    * Ajoutez des données\n",
        "                    * Entraînez moins longtemps (arrêt précoce)\n",
        "                    * Réduisez la complexité du modèle (régularisez)\n",
        "                * NON (continuez tout va bien)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKhjAoywgKe2"
      },
      "source": [
        "### Évaluation finale du modèle avec les données de test\n",
        "\n",
        "Nous avons retenu une partie des données dans le jeu de données de test que l'algorithme n'a pas touchées. Nous utiliserons ces données pour avoir une idée des performances du modèle sur des données inconnues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "wciU9ldMgKe2"
      },
      "source": [
        "# Inspiration: https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "print(\"Version de XGBoost\",xgb.__version__)\n",
        "\n",
        "# Creation d'une liste de modèles\n",
        "modeles = []\n",
        "classification_logistique = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "modeles.append((\"Classification logistique\",classification_logistique))\n",
        "foret_aleatoire = RandomForestClassifier()\n",
        "modeles.append((\"Forêt aléatoire\",foret_aleatoire))\n",
        "arbres_dopage_gradient = xgb.XGBClassifier(use_label_encoder=False,eval_metric='mlogloss')\n",
        "modeles.append((\"Arbres à gradient dopé - XGBoost\",arbres_dopage_gradient))\n",
        "\n",
        "# Boucle d'entraînement et de validation croisée\n",
        "resultats = []\n",
        "noms_modeles = []\n",
        "print(\"Entraînement des différents modèles...\\n\")\n",
        "print(\"Résultats de la validation croisée:\\n\")\n",
        "for nom_modele, modele in modeles:\n",
        "    validation_croisee = StratifiedKFold(n_splits=5,\n",
        "                                         random_state=42,\n",
        "                                         shuffle=True)\n",
        "    resultat_vc = cross_val_score(modele,\n",
        "                                  predicteurs_ent,\n",
        "                                  cibles_ent,\n",
        "                                  cv=validation_croisee,\n",
        "                                  scoring='accuracy')\n",
        "    resultats.append(resultat_vc)\n",
        "    noms_modeles.append(nom_modele)\n",
        "    print('>  %s: %f (%f)' % (nom_modele, resultat_vc.mean(), resultat_vc.std()))\n",
        "\n",
        "print(\"\\n\",\"*\"*100)\n",
        "print(\"\\nValidation avec les données de test...\\n\")\n",
        "for nom_modele, modele in modeles:\n",
        "    modele.fit(predicteurs_ent, cibles_ent)\n",
        "    test_predictions = modele.predict(predicteurs_test)\n",
        "    print('>  %s: - Erreur de classification sur les données test: %d' %\n",
        "          (nom_modele, (cibles_test != test_predictions).sum()))\n",
        "    print('>  %s- Exactitude: %.2f' %\n",
        "          (nom_modele, accuracy_score(cibles_test, test_predictions)))\n",
        "    # Affichage d'une matrice de confusion et d'un rapport de classification\n",
        "    print(\"Matrice de confusion:\\n\")\n",
        "    afficher_matrice_confusion(confusion_matrix(cibles_test, test_predictions),['Iris-setosa','Iris-versicolor', 'Iris-virginica'])\n",
        "    print(\"\\nRapport de classification:\\n\",classification_report(cibles_test, test_predictions))\n",
        "    print(\"-\"*90,\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpbIYgVPgKe3"
      },
      "source": [
        "## Ressources utiles\n",
        "\n",
        "1) StackOverflow - https://stackoverflow.com\n",
        "\n",
        "2) Pandas - tutoriels - https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html\n",
        "\n",
        "3) Expressions régulières - http://regex101.com/ - https://www.regular-expressions.info/tutorial.html\n",
        "\n",
        "4) Matplotlib - tutoriels - https://matplotlib.org/3.1.1/tutorials/index.html\n",
        "\n",
        "5) Scikit-Learn (ou Sklearn) - <a href=\"https://scikit-learn.org/stable/\">Scikit-Learn</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4_hfIf9gKe3"
      },
      "source": [
        "print(\"Exécution du carnet web IPython terminée\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9eWw0SGzomA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}